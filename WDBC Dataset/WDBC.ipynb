{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikechen/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n",
      "(569,)\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# To extract data, we can use pandas's dataframe\n",
    "# Here, I learned that data.iloc is a useful method to extract data\n",
    "data=pd.read_csv('./data.txt',header=None)\n",
    "print(data.shape)\n",
    "label = pd.factorize(data[1])[0]\n",
    "print(label.shape)\n",
    "feature = data.iloc[:,2:]\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((400, 30), (400,))\n",
      "((169, 30), (169,))\n"
     ]
    }
   ],
   "source": [
    "# Split testing and training data\n",
    "# Typically, we can manually extract first 169 samples to be test set \n",
    "# But here is a better method called train_test_split in sklearn, which can do this more randomly\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(feature,label,test_size=0.297)\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to apply PCA using sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "pca_original = PCA(n_components=30,svd_solver='randomized',whiten=True)\n",
    "pca_original.fit(train_X)\n",
    "pca_3 = PCA(n_components=3,svd_solver='randomized',whiten=True).fit(train_X)\n",
    "pca_5 = PCA(n_components=5,svd_solver='randomized',whiten=True).fit(train_X)\n",
    "pca_7 = PCA(n_components=7,svd_solver='randomized',whiten=True).fit(train_X)\n",
    "pca_9 = PCA(n_components=9,svd_solver='randomized',whiten=True).fit(train_X)\n",
    "pca_11 = PCA(n_components=11,svd_solver='randomized',whiten=True).fit(train_X)\n",
    "\n",
    "train_X = pca_original.transform(train_X)\n",
    "test_X = pca_original.transform(test_X)\n",
    "train_X_3 = pca_3.transform(train_X)\n",
    "test_X_3 = pca_3.transform(test_X)\n",
    "train_X_5 = pca_5.transform(train_X)\n",
    "test_X_5 = pca_5.transform(test_X)\n",
    "train_X_7 = pca_7.transform(train_X)\n",
    "test_X_7 = pca_7.transform(test_X)\n",
    "train_X_9 = pca_9.transform(train_X)\n",
    "test_X_9 = pca_9.transform(test_X)\n",
    "train_X_11 = pca_11.transform(train_X)\n",
    "test_X_11 = pca_11.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 30)\n",
      "(400, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_X_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "# Do K-fold validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(train_X.shape[0])\n",
    "\n",
    "def kfold_clf(clf, X, Y):\n",
    "    kf = KFold(X.shape[0], n_folds=10, shuffle=False)\n",
    "    # The method of using kf, using enumerate\n",
    "    # f1 value store in the following arrays\n",
    "    validation_f1 = np.zeros((10, 1))\n",
    "    train_f1 = np.zeros((10, 1))\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        train_X = X[train_index]\n",
    "        train_Y = Y[train_index]\n",
    "        validation_X = X[test_index]\n",
    "        validation_Y = Y[test_index]\n",
    "        clf.fit(train_X, train_Y)\n",
    "        train_pred = clf.predict(train_X)\n",
    "        validation_pred = clf.predict(validation_X)\n",
    "        train_f1[i, 0] = f1_score(train_Y, train_pred)\n",
    "        validation_f1[i, 0] = f1_score(validation_Y, validation_pred)\n",
    "    print('\\tthe average f1 score on train set= %.3f'%(train_f1.mean()))\n",
    "    print('\\tthe average f1 score on validation set =.%3f'%(validation_f1.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree=DecisionTreeClassifier()\n",
    "decision_tree_3=DecisionTreeClassifier()\n",
    "decision_tree_5=DecisionTreeClassifier()\n",
    "decision_tree_7=DecisionTreeClassifier()\n",
    "decision_tree_9=DecisionTreeClassifier()\n",
    "decision_tree_11=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tthe average f1 score on train set= 1.000\n",
      "\tthe average f1 score on validation set =.0.931748\n",
      "\tthe average f1 score on train set= 1.000\n",
      "\tthe average f1 score on validation set =.0.704366\n",
      "\tthe average f1 score on train set= 1.000\n",
      "\tthe average f1 score on validation set =.0.722340\n",
      "\tthe average f1 score on train set= 1.000\n",
      "\tthe average f1 score on validation set =.0.798272\n",
      "\tthe average f1 score on train set= 1.000\n",
      "\tthe average f1 score on validation set =.0.802273\n",
      "\tthe average f1 score on train set= 1.000\n",
      "\tthe average f1 score on validation set =.0.814103\n",
      "[0.923076923076923, 0.6494845360824743, 0.7363184079601991, 0.8155339805825242, 0.8256880733944955, 0.8202764976958525]\n"
     ]
    }
   ],
   "source": [
    "dt_list=[decision_tree,decision_tree_3,decision_tree_5,decision_tree_7,decision_tree_9,decision_tree_11]\n",
    "train_list=[train_X, train_X_3, train_X_5, train_X_7, train_X_9, train_X_11]\n",
    "test_list=[test_X, test_X_3, test_X_5, test_X_7, test_X_9, test_X_11]\n",
    "f1_score_list=[]\n",
    "\n",
    "for i in range(6):\n",
    "    kfold_clf(dt_list[i], train_list[i], train_Y)\n",
    "    test_pred = dt_list[i].predict(test_list[i])\n",
    "    f1=f1_score(test_Y,test_pred)\n",
    "    f1_score_list.append(f1)\n",
    "print(f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
